{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitcoing Price Predictor\n",
    "\n",
    "\n",
    "We want to predict the price of bitcoin using historical bitcoin data as well as its sentiment analysis over time. We are planning on experimenting with time series models such as LSTM to predict token price. To measure sentiment analysis, we will be using the fear and greed API which measures engagement with Bitcoin. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math # Mathematical functions \n",
    "import numpy as np # Fundamental package for scientific computing with Python\n",
    "import pandas as pd # Additional functions for analysing and manipulating data\n",
    "from datetime import date, timedelta, datetime # Date Functions\n",
    "from pandas.plotting import register_matplotlib_converters # This function adds plotting functions for calender dates\n",
    "import matplotlib.pyplot as plt # Important package for visualization - we use this to plot the market data\n",
    "import matplotlib.dates as mdates # Formatting dates\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error # Packages for measuring model performance / errors\n",
    "from keras.models import Sequential # Deep learning library, used for neural networks\n",
    "from keras.layers import LSTM, Dense, Dropout # Deep learning classes for recurrent and regular densely-connected layers\n",
    "# from keras.callbacks import EarlyStopping # EarlyStopping during model training\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler # This Scaler removes the median and scales the data according to the quantile range to normalize the price data \n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting and Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv\n",
    "df = pd.read_csv(\"data/bitstampUSD_1-min_data_2012-01-01_to_2021-03-31.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp              int64\n",
      "Open                 float64\n",
      "High                 float64\n",
      "Low                  float64\n",
      "Close                float64\n",
      "Volume_(BTC)         float64\n",
      "Volume_(Currency)    float64\n",
      "Weighted_Price       float64\n",
      "dtype: object\n",
      "(4857377, 8)\n",
      "Timestamp              int64\n",
      "Open                 float64\n",
      "High                 float64\n",
      "Low                  float64\n",
      "Close                float64\n",
      "Volume_(BTC)         float64\n",
      "Volume_(Currency)    float64\n",
      "Weighted_Price       float64\n",
      "dtype: object\n",
      "(3613769, 8)\n"
     ]
    }
   ],
   "source": [
    "#drop NA values \n",
    "print(df.dtypes)\n",
    "print(df.shape) #(4857377, 8)\n",
    "df = df.dropna()\n",
    "print(df.dtypes)\n",
    "print(df.shape) #(3613769, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexing Batches\n",
    "df.set_index('Timestamp', inplace=True)\n",
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of considered Features\n",
    "FEATURES = ['Open','High','Low','Close','Volume_(BTC)','Volume_(Currency)','Weighted_Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset with features and filter the data to the list of FEATURES\n",
    "data_filtered = df[FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add a prediction column and set dummy values to prepare the data for scaling\n",
    "data_filtered_ext = data_filtered.copy()\n",
    "data_filtered_ext['Prediction'] = data_filtered_ext['Weighted_Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the tail of the dataframe\n",
    "# print(data_filtered_ext.tail())\n",
    "\n",
    "# Get the number of rows in the data\n",
    "nrows = data_filtered.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3613769, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert the data to numpy values\n",
    "np_data_unscaled = np.array(data_filtered)\n",
    "np_data = np.reshape(np_data_unscaled, (nrows, -1))\n",
    "print(np_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data by scaling each feature to a range between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "np_data_scaled = scaler.fit_transform(np_data_unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a separate scaler that works on a single column for scaling predictions\n",
    "scaler_pred = MinMaxScaler()\n",
    "df_Close = pd.DataFrame(data_filtered_ext['Weighted_Price'])\n",
    "np_Close_scaled = scaler_pred.fit_transform(df_Close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the sequence length - this is the timeframe used to make a single prediction\n",
    "sequence_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Index\n",
    "index_Close = data.columns.get_loc(\"Weighted_Price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data into train and train data sets\n",
    "# As a first step, we get the number of rows to train the model on 80% of the data \n",
    "train_data_len = math.ceil(np_data_scaled.shape[0] * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training and test data\n",
    "train_data = np_data_scaled[0:train_data_len, :]\n",
    "test_data = np_data_scaled[train_data_len - sequence_length:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The RNN needs data with the format of [samples, time steps, features]\n",
    "# Here, we create N samples, sequence_length time steps per sample, and 6 features\n",
    "def partition_dataset(sequence_length, data):\n",
    "    x, y = [], []\n",
    "    data_len = data.shape[0]\n",
    "    for i in range(sequence_length, data_len):\n",
    "        x.append(data[i-sequence_length:i,:]) #contains sequence_length values 0-sequence_length * columsn\n",
    "        y.append(data[i, index_Close]) #contains the prediction values for validation,  for single-step prediction\n",
    "    \n",
    "    # Convert the x and y to numpy arrays\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training data and test data\n",
    "x_train, y_train = partition_dataset(sequence_length, train_data)\n",
    "x_test, y_test = partition_dataset(sequence_length, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2890966, 50, 7) (2890966,)\n",
      "(722753, 50, 7) (722753,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes: the result is: (rows, training_sequence, features) (prediction value, )\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.375133305987339e-05\n",
      "4.375133305987339e-05\n"
     ]
    }
   ],
   "source": [
    "# Validate that the prediction value and the input match up\n",
    "# The last close price of the second input sample should equal the first prediction value\n",
    "print(x_train[1][sequence_length-1][index_Close])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the neural network model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350 50 7\n"
     ]
    }
   ],
   "source": [
    "# Model with n_neurons = inputshape Timestamps, each with x_train.shape[2] variables\n",
    "n_neurons = x_train.shape[1] * x_train.shape[2]\n",
    "print(n_neurons, x_train.shape[1], x_train.shape[2])\n",
    "model.add(LSTM(n_neurons, return_sequences=True)) \n",
    "model.add(LSTM(n_neurons, return_sequences=False))\n",
    "model.add(Dense(5))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b346b40471ba213f5e961a5d782728ceb56ae92186b2dfa6f5b328dd50df76d4"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
